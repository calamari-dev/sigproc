\documentclass[../../main]{subfiles}

\begin{document}
\chapter{数ベクトル空間}
\label{chapter:numerical_vector_space}

\begin{lead}
  \cref{chapter:numerical_vector_space}では，数ベクトル空間における直交性と最良近似の関係を説明する．
\end{lead}

\section{直交射影}

本節では，あるベクトルを他のベクトルの線型結合で近似する手法を説明する．
特に断りのない限り，\cref{chapter:numerical_vector_space}において\(\numset{K}\)は\(\numset{R}\)か\(\numset{C}\)を意味し，
\(\innerp{\holder}{\holder}\)は\(\numset{K}^n\)の標準内積を意味する．また
\[
  \vnorm{\vect{x}} = \sqrt{\innerp{\vect{x}}{\vect{x}}}
  = \sqrt{\abs{x_1}^2+\dots+\abs{x_n}^2}
  \quad(\vect{x}=\trps{\matrice{x_1 & \cdots & x_n}}\in\numset{K}^n)
\]
とする\indexsymbol{\(\vnorm{\holder}\)}．

\subsection{直交射影}

\(\numset{K}^n\)のベクトル\(\vect{x}\)，部分空間\(V\)が与えられたとき，\(V\)の元で\(\vect{x}\)に最も近いベクトル，すなわち，距離\(\vnorm{\vect{x}-\vect{m}}\)を最小にする\(\vect{m}\in V\)について考えよう．

\begin{figure}[htbp]
  \centering
  \includegraphics{proj2d.pdf}
  \caption{\(V=\spannedby\Set{\vect{v}}\)の元で\(\vect{x}\)に最も近いベクトル\(\vect{m}\)の様子．}
  \label{figure:proj2d}
\end{figure}

\(\numset{K}^n\)が平面\(\numset{R}^2\)で，\(V\)があるベクトル\(\vect{v}\neq\zvec\)により生成される直線\(\spannedby\Set{\vect{v}}\)の場合について，\(\vect{m}\)を図示したのが\cref{figure:proj2d}である．
\cref{figure:proj2d}を見ると，\(\vect{x}-\vect{m}\)は\(\vect{v}\)と直交しているのが分かる．

一般の部分空間\(V\subset\numset{K}^n\)についても，直交性は最良近似を特徴づける．証明へと入る前に，便利な記法を2つ定義しておく．

\begin{definition}{argmin，argmax}{argmin_argmax}\index{argmin@\(\argmin f(x)\)}\index{argmax@\(\argmax f(x)\)}
  実数値関数\(f\)は集合\(S\)を定義域に含むとする．\(S\)の部分集合\(\argmin_{x\in S}f(x)\)，\(\argmax_{x\in S}f(x)\)を以下の通り定義する．
  \begin{gather*}
    \argmin_{x\in S}f(x) = \Set{x\in S\given\text{任意の\(y\in S\)に対して\(f(y)\geq f(x)\)}}, \\
    \argmax_{x\in S}f(x) = \Set{x\in S\given\text{任意の\(y\in S\)に対して\(f(y)\leq f(x)\)}}
  \end{gather*}
\end{definition}

\cref{definition:argmin_argmax}からただちに，次のことが分かる．

\begin{proposition}{}{}
  \(S\)の元\(a\)に関する以下の条件は同値であり，同様のことが\(\argmax\)についても成り立つ．
  \begin{enumerate}
    \item \(a\in\argmin_{x\in S}f(x)\)である．
    \item \(f(a)\)は集合\(\Set{f(x)\given x\in S}\)の下限であり，よって最小元でもある．
  \end{enumerate}
\end{proposition}

\begin{example}
  \(\argmin_{x\in\coival{0}{\infty}}\exp(-x)=\argmax_{x\in\coival{0}{\infty}}\exp(x)=\emptyset\)である．
  また\(\argmin_{x\in\numset{R}}\abs{\sin(x)}=\Set{n\krez\given n\in\numset{Z}}\)である．
\end{example}

\begin{figure}[htbp]
  \centering
  \includegraphics{argmin.pdf}
  \caption{\(\exp(-x)\)と\(\abs{\sin(x)}\)のグラフ．\(\exp(-x)\to 0\)（\(x\to\infty\)）であるが，\(\exp(-x)=0\)となる実数\(x\)は存在しないことに注意．}
\end{figure}

\(\numset{K}=\numset{R}\)の場合も同様に証明できるので，\cref{proposition:finite_projection}まで証明では\(\numset{K}=\numset{C}\)を仮定する．また，部分空間が\(\Set{\zvec}\)でないことも仮定する．

\begin{proposition}{}{finite_convex_projection}
  \(\vect{x}\in\numset{K}^n\)かつ，\(V\)は\(\numset{K}^n\)の部分空間とする．
  このとき，\(\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)はただ1つの元からなる集合である．
\end{proposition}

\begin{proof}
  \(\basis{B}=\Set{\vect{e}_1,\dots,\vect{e}_m}\)を\(V\)の正規直交基底とすると，
  \(V\)は\(\Set{z_1\vect{e}_1+\dots+z_m\vect{e}_m\given z_1,\dots,z_m\in\numset{C}}\)と書ける．
  したがって，\(f(z_1,\dots,z_m)=\vnorm{\vect{x}-(z_1\vect{e}_1+\dots+z_m\vect{e}_m)}\)（\(z_1,\dots,z_m\in\numset{C}\)）とおくと
  \[
    \argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}} = \Set*{z_1\vect{e}_1+\dots+z_m\vect{e}_m\given\trps{\matrice{z_1 & \cdots & z_m}}\in\argmin_{\vect{z}\in\numset{C}^m}f(\vect{z})}
  \]
  である．

  \(\argmin_{\vect{z}\in\numset{C}^m}f(\vect{z})\)を求める．\(\innerp{\vect{e}_i}{\vect{e}_j}=\kdelta{i}{j}\)だから
  \[
    \vnorm*{\sum_{i=1}^mz_i\vect{e}_i}^2 = \innerp*{\sum_{i=1}^mz_i\vect{e}_i}{\sum_{j=1}^mz_j\vect{e}_j}
    = \sum_{i=1}^mz_i\sum_{j=1}^m\conj{z}_j\innerp{\vect{e}_i}{\vect{e}_j}
    = \sum_{i=1}^mz_i\conj{z}_i
    = \sum_{i=1}^m\abs{z_i}^2
  \]
  である．したがって（\(\sum_{k=1}^m\)を\(\sum\)と略記すると）
  \begin{align*}
    f(\vect{z})^2 &= \vnorm*{\vect{x}-\sum z_k\vect{e}_k}^2 = \vnorm{\vect{x}}^2-2\rpart\innerp*{\vect{x}}{\sum z_k\vect{e}_k}+\vnorm*{\sum z_k\vect{e}_k}^2 \\
    &= \vnorm{\vect{x}}^2-2\sum\rpart[\conj{z}_k\innerp{\vect{x}}{\vect{e}_k}]+\sum\abs{z_k}^2
  \end{align*}
  である．よって，\(f(\vect{z})^2\)は\(s_k=\rpart z_k\)と\(t_k=\ipart z_k\)の式で
  \begin{align*}
    f(\vect{z})^2 &= \vnorm{\vect{x}}^2+\sum(-2\rpart[(s_k-\iuni t_k)\innerp{\vect{x}}{\vect{e}_k}]+s_k^2+t_k^2) \\
    &= \vnorm{\vect{x}}^2+\sum(-2(s_k\rpart\innerp{\vect{x}}{\vect{e}_k}+t_k\ipart\innerp{\vect{x}}{\vect{e}_k})+s_k^2+t_k^2) \\
    &= \vnorm{\vect{x}}^2+\sum((s_k-\rpart\innerp{\vect{x}}{\vect{e}_k})^2+(t_k-\ipart\innerp{\vect{x}}{\vect{e}_k})^2-\abs{\innerp{\vect{x}}{\vect{e}_k}}^2)
  \end{align*}
  と書けるので，次式が成立する．
  \begin{equation}
    \label{equation:pre_bessels_inequality}
    f(\vect{z})^2 = \vnorm{\vect{x}}^2+\sum_{k=1}^m\abs{z_k-\innerp{\vect{x}}{\vect{e}_k}}^2-\sum_{k=1}^m\abs{\innerp{\vect{x}}{\vect{e}_k}}^2
  \end{equation}

  \cref{equation:pre_bessels_inequality}より\(\argmin_{\vect{z}\in\numset{C}^m}f(\vect{z})=\Set{\trps{\rowvect{\innerp{\vect{x}}{\vect{e}_1} & \cdots & \innerp{\vect{x}}{\vect{e}_m}}}}\)であるから，
  \(\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}=\Set{\innerp{\vect{x}}{\vect{e}_1}\vect{e}_1+\dots+\innerp{\vect{x}}{\vect{e}_m}\vect{e}_m}\)である．
\end{proof}

なお，\cref{proposition:finite_convex_projection}は部分空間よりも少し広い対象（閉凸集合）へと一般化できるのだが，そのことは\cref{xr-chapter:hilbert_space}であらためて扱う．

\begin{proposition}{}{weak_finite_projection}
  \(\vect{x}\in\numset{K}^n\)かつ，\(V\)は\(\numset{K}^n\)の部分空間とする．
  \(V\)のある元\(\vect{m}\)が任意の\(\vect{v}\in V\)に対して\(\innerp{\vect{x}-\vect{m}}{\vect{v}}=0\)を満たすとき，
  \(\vect{m}\in\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)である．
\end{proposition}

\begin{proof}
  任意に\(\vect{y}\in V\)をとり，\(\vect{e}=\vect{y}-\vect{m}\)とおく．すると，\(\innerp{\vect{x}-\vect{m}}{\vect{e}}=0\)より
  \(\vnorm{\vect{x}-\vect{y}}^2=\vnorm{\vect{x}-\vect{m}-\vect{e}}^2=\vnorm{\vect{x}-\vect{m}}^2-2\rpart\innerp{\vect{x}-\vect{m}}{\vect{e}}+\vnorm{\vect{e}}^2=\vnorm{\vect{x}-\vect{m}}^2+\vnorm{\vect{e}}^2\)
  が成立する．よって\(\vnorm{\vect{x}-\vect{y}}^2\geq\vnorm{\vect{x}-\vect{m}}^2\)だから，\(\vect{m}\in\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)である．
\end{proof}

\cref{proposition:weak_finite_projection}からは，仮定「任意の\(\vect{v}\in V\)に対して\(\innerp{\vect{x}-\vect{m}}{\vect{v}}=0\)」を満たす\(\vect{m}\in V\)が存在するかどうかは分からない．
しかし実は，仮定を満たす\(\vect{m}\)は一意に存在し，それは\(\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)のただ1つの元である．

\begin{proposition}{}{finite_projection}
  \(\vect{x}\in\numset{K}^n\)かつ，\(V\)は\(\numset{K}^n\)の部分空間とする．
  このとき，\(V\)の元\(\vect{m}\)に関する以下の条件は同値であり，条件を満たす\(\vect{m}\)はただ1つ存在する．
  \begin{enumerate}
    \item \(\vect{m}\in\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)である．
    \item 任意の\(\vect{v}\in V\)に対して\(\innerp{\vect{x}-\vect{m}}{\vect{v}}=0\)である．
  \end{enumerate}
\end{proposition}

\begin{proof}
  \cref{proposition:finite_convex_projection}より，\(\vect{n}\in\argmin_{\vect{y}\in V}\vnorm{\vect{x}-\vect{y}}\)を満たす\(\vect{n}\)がただ1つ存在する．
  そして\cref{proposition:weak_finite_projection}より，\(\vect{m}\in V\)が任意の\(\vect{v}\in V\)に対して\(\innerp{\vect{x}-\vect{m}}{\vect{v}}=0\)を満たすなら\(\vect{m}=\vect{n}\)である．

  したがって，\(\vect{n}\)がすべての\(\vect{v}\in V\)に対して\(\innerp{\vect{x}-\vect{n}}{\vect{v}}=0\)を満たすことを示せばよい．それには\(\vnorm{\vect{v}}=1\)のときについて示せば十分である．
  \(\vect{n}\)の定義から，関数\(e(z)=\vnorm{\vect{x}-(\vect{n}+z\vect{v})}^2-\vnorm{\vect{x}-\vect{n}}^2\)（\(z\in\numset{C}\)）は負の値をとらない．一方，\(x=\rpart z\)，\(y=\ipart z\)とおくと
  \begin{align*}
    e(z) &= \vnorm{\vect{x}-\vect{n}-z\vect{v}}^2-\vnorm{\vect{x}-\vect{n}}^2
    = -2\rpart[(x-\iuni y)\innerp{\vect{x}-\vect{n}}{\vect{v}}]+\abs{z}^2\vnorm{\vect{v}}^2 \\
    &= -2(x\rpart\innerp{\vect{x}-\vect{n}}{\vect{v}}+y\ipart\innerp{\vect{x}-\vect{n}}{\vect{v}})+x^2+y^2 \\
    &= (x-\rpart\innerp{\vect{x}-\vect{n}}{\vect{v}})^2+(y-\ipart\innerp{\vect{x}-\vect{n}}{\vect{v}})^2-\abs{\innerp{\vect{x}-\vect{n}}{\vect{v}}}^2 \\
    &= \abs{z-\innerp{\vect{x}-\vect{n}}{\vect{v}}}^2-\abs{\innerp{\vect{x}-\vect{n}}{\vect{v}}}^2
  \end{align*}
  なので\(\abs{\innerp{\vect{x}-\vect{n}}{\vect{v}}}^2=-e(\innerp{\vect{x}-\vect{n}}{\vect{v}})\leq 0\)，よって\(\innerp{\vect{x}-\vect{n}}{\vect{v}}=0\)である．
\end{proof}

\begin{definition}{直交射影}{finite_projection}\index{ちょっこうしゃえい@直交射影}\index{proj@\(\proj_V(\vect{x})\)}
  \cref{proposition:finite_projection}の\(\vect{m}\)を\(\vect{x}\)の\(V\)への\termdef{直交射影}（orthogonal projection）といい，\(\proj_V(\vect{x})\)と表す．
\end{definition}

\begin{figure}[htbp]
  \centering
  \includegraphics{proj3d.pdf}
  \caption{\(\vect{x}\)の\(V=\spannedby\Set{\vect{v}_1,\vect{v}_2}\)への直交射影\(\vect{m}=\proj_V(\vect{x})\)の模式図．}
\end{figure}

\begin{example}
  \(\vect{e}_x=\trps{\rowvect{1 & 0 & 0}}\)，\(\vect{e}_y=\trps{\rowvect{0 & 1 & 0}}\)とし，
  \(\numset{R}^3\)の部分空間\(V\)を\(V=\spannedby\Set{\vect{e}_x,\vect{e}_y}\)で定義する．
  このとき，集合\(\Set{\vect{e}_x,\vect{e}_y}\)は\(V\)の正規直交基底なので
  \[
    \proj_V(\vect{r}) = \innerp{\vect{r}}{\vect{e}_x}\vect{e}_x+\innerp{\vect{r}}{\vect{e}_y}\vect{e}_y
    = \trps{\matrice{s & t & 0}}
    \quad(\vect{r}=\trps{\matrice{s & t & u}}\in\numset{R}^3)
  \]
  である．
\end{example}

\begin{proposition}{}{}
  \(\numset{K}^n\)の任意の部分空間\(V\)について，写像\(\proj_V\colon\numset{K}^n\to V\)は線型写像である．
\end{proposition}

\begin{proof}
  \(s,t\in\numset{K}\)，\(\vect{x},\vect{y}\in\numset{K}^n\)を任意にとり，\(\vect{m}=s\proj_V(\vect{x})+t\proj_V(\vect{y})\)とおく．
  このとき，任意の\(\vect{v}\in V\)に対して\(\innerp{s\vect{x}+t\vect{y}-\vect{m}}{\vect{v}}=s\innerp{\vect{x}-\proj_V(\vect{x})}{\vect{v}}+t\innerp{\vect{y}-\proj_V(\vect{y})}{\vect{v}}=s0+t0=0\)となるので，
  \cref{proposition:finite_projection}より\(\proj_V(s\vect{x}+t\vect{y})=\vect{m}\)である．よって，\(\proj_V\)は線型写像である．
\end{proof}

\subsection{直交補空間}

\begin{definition}{直交補空間}{numerical_perpendicular_complement}\index{ちょっこうほくうかん@直交補空間}\indexsymbol{\(\pcomp{V}\)}\indexsymbol{\(\pcomp[V]{W}\)}
  \(V\)は\(\numset{K}^n\)の部分空間とする．\(W\)が\(V\)の部分空間なら，集合
  \[
    X = \Set{\vect{v}\in V\given\text{任意の\(\vect{w}\in W\)に対して\(\innerp{\vect{v}}{\vect{w}}=0\)}}
  \]
  も\(V\)の部分空間になる．\(X\)を（\(V\)における）\(W\)の\termdef{直交補空間}（orthogonal complement）といい，\(\pcomp[V]{W}\)と表記する．誤解のおそれがなければ，\(\pcomp[V]{W}\)を\(\pcomp{W}\)とも書く．
\end{definition}

\begin{example}
  \(W=\spannedby\Set{\vect{e}_1,\vect{e}_2}\)を\(\numset{R}^3\)の2次元部分空間とする．
  このとき，\(\numset{R}^3\)における\(W\)の直交補空間は\(\vect{e}_1\)と\(\vect{e}_2\)に直交する\(\zvec\)でないベクトル\(\vect{e}_3\)で生成される直線\(\spannedby\Set{\vect{e}_3}\)である．
  特に\(\vect{e}_1\)と\(\vect{e}_2\)が直交するとき，集合\(\Set{\vect{e}_i/\vnorm{\vect{e}_i}\given i=1,2,3}\)は\(\numset{R}^3\)の正規直交基底である．
\end{example}

\begin{figure}[htbp]
  \centering
  \includegraphics{orthogonal_complement.pdf}
  \caption{\(W\)と\(\vect{e}_1\)，\(\vect{e}_2\)，\(\vect{e}_3\)の様子．}
\end{figure}

\begin{proposition}{}{}
  \(V\)は\(\numset{K}^n\)の部分空間で，\(W\)は\(V\)の部分空間とする．このとき\(V=W\oplus\pcomp[V]{W}\)である．
\end{proposition}

\begin{proof}
  \(\vect{x}\in W\cap\pcomp{W}\)なら\(\innerp{\vect{x}}{\vect{x}}=0\)なので\(\vect{x}=\zvec\)，よって\(W\cap\pcomp{W}=\Set{\zvec}\)である．
  また\cref{proposition:finite_projection}より，任意の\(\vect{x}\in V\)に対して\(\vect{x}-\proj_W(\vect{x})\in\pcomp{W}\)，\(\vect{x}=\proj_W(\vect{x})+(\vect{x}-\proj_W(\vect{x}))\in W+\pcomp{W}\)である．
  したがって\(V=W\oplus\pcomp{W}\)である．
\end{proof}

\subsection{分析と合成}

\cref{proposition:finite_convex_projection}の証明では，\(\proj_V(\vect{x})\)の存在を示すために\(V\)の正規直交基底\(\basis{B}=\Set{\vect{e}_1,\dots,\vect{e}_m}\)を1つ選び，\(\proj_V(\vect{x})\)を\(\sum_{i=1}^m\innerp{\vect{x}}{\vect{e}_i}\vect{e}_i\)と表した．
一方で（特に信号解析では），\(\vect{x}\)の性質を調べるのに利用したい\(\numset{C}^n\)の正規直交基底\(\basis{B}=\Set{\vect{e}_1,\dots,\vect{e}_n}\)があって，
そこから部分空間\(V_m=\spannedby\Set{\vect{e}_1,\dots,\vect{e}_m}\)（\(m=1,\dots,n\)）への直交射影\(\proj_{V_m}(\vect{x})\)を作ることも多い．そのような場合，直交射影は3つの操作に分解できる．

\begin{definition}{エルミート転置}{hermitian_transpose}\index{えるみーとてんち@エルミート転置}\index{ずいはんぎょうれつ@随伴行列|see{エルミート転置}}\index{H@\(\htrps{\mat{A}}\)}
  \(\mat{A}\)を\(m\times n\)複素行列とする．\(n\times m\)行列\(\trps{\conj{\mat{A}}}\)を\(\mat{A}\)の\termdef{エルミート転置}（Hermitian transpose）といい，\(\htrps{\mat{A}}\)と表す\footnotemark ．
\end{definition}

\footnotetext{エルミート転置は\termdef{随伴行列}（adjoint matrix）と呼ばれることも多いが，別の行列を随伴行列と呼ぶ流儀もあり，まぎらわしい．そのため，本書ではエルミート転置で統一する．}

\(\mat{U}=\htrps{\rowvect{\vect{e}_1 & \cdots & \vect{e}_n}}\)，\(\mat{\Lambda}=\begin{bsmallmatrix}\imat_m & \\ & \zmat_{n-m}\end{bsmallmatrix}\)とおく（\(\imat_m\)は\(m\)次単位行列，\(\zmat_{n-m}\)は\(n-m\)次零行列）．
このとき，任意の\(\vect{x}=\trps{\rowvect{x_1 & \cdots & x_n}}\in\numset{C}^n\)に対して
\[
  \mat{U}\vect{x} = \matrice*{\htrps{\vect{e}_1}\vect{x} \\ \vdots \\ \htrps{\vect{e}_n}\vect{x}}
  = \matrice*{\innerp{\vect{x}}{\vect{e}_1} \\ \vdots \\ \innerp{\vect{x}}{\vect{e}_n}},
  \quad\mat{\Lambda}\vect{x} = \matrice*{x_1 \\ \vdots \\ x_m \\ \zvec},
  \quad\htrps{\mat{U}}\vect{x} = \htrps{\mat{U}}\matrice*{x_1 \\ \vdots \\ x_n}
  = \sum_{i=1}^nx_i\vect{e}_i
\]
であるから
\[
  \htrps{\mat{U}}\mat{\Lambda}\mat{U}\vect{x} = \htrps{\mat{U}}\mat{\Lambda}\matrice*{\innerp{\vect{x}}{\vect{e}_1} \\ \vdots \\ \innerp{\vect{x}}{\vect{e}_n}}
  = \htrps{\mat{U}}\matrice*{\innerp{\vect{x}}{\vect{e}_1} \\ \vdots \\ \innerp{\vect{x}}{\vect{e}_m} \\ \zvec}
  = \sum_{i=1}^m\innerp{\vect{x}}{\vect{e}_i}\vect{e}_i
  = \proj_{V_m}(\vect{x})
\]
であり，\(\proj_{V_m}(\vect{x})=\htrps{\mat{U}}\mat{\Lambda}\mat{U}\vect{x}\)が成立する．言い換えれば，\(\proj_{V_m}\)は\(\numset{C}^n\)から\(\numset{C}^n\)への3つの写像
\(T(\vect{x})=\mat{U}\vect{x}\)，\(L(\vect{x})=\mat{\Lambda}\vect{x}\)，\(\synth{T}(\vect{x})=\htrps{\mat{U}}\vect{x}\)を用いて，\(\proj_{V_m}=\synth{T}LT\)と表せる．

\(T(\vect{x})\)の第\(i\)成分\(\innerp{\vect{x}}{\vect{e}_i}\)は，\(\vect{x}\)に含まれる\(\vect{e}_i\)の「成分」を表すと考えられる．その理由は2つある．
1つめの理由は，\(\vnorm{\proj_{\spannedby\Set{\vect{e}_i}}(\vect{x})}=\vnorm{\innerp{\vect{x}}{\vect{e}_i}\vect{e}_i}=\abs{\innerp{\vect{x}}{\vect{e}_i}}\)なので，
\(\abs{\innerp{\vect{x}}{\vect{e}_i}}\)が\(\vect{e}_i\)のスカラー倍で\(\vect{x}\)を最もよく近似するベクトルの長さを表すことである．
もう1つの理由は，\(\basis{B}\)は\(\numset{K}^n\)の正規直交基底であるから
\[
  \vect{x} = \proj_{V_n}(\vect{x})
  = \sum_{i=1}^n\innerp{\vect{x}}{\vect{e}_i}\vect{e}_i
\]
が成立し，\(\innerp{\vect{x}}{\vect{e}_i}\vect{e}_i\)の和で\(\vect{x}\)が表されることである．

以上の理由から，本書では線型写像\(T(\vect{x})=\trps{\rowvect{\innerp{\vect{x}}{\vect{e}_1} & \cdots & \innerp{\vect{x}}{\vect{e}_n}}}\)を分析作用素，\(\synth{T}(\vect{x})=\sum_{i=1}^nx_i\vect{e}_i\)を合成作用素と呼ぶ．

\begin{definition}{分析作用素，合成作用素}{analysis_and_synthesis}\index{ぶんせきさようそ@分析作用素}\index{ごうせいさようそ@合成作用素}
  \(\basis{B}=\Set{\vect{e}_1,\dots,\vect{e}_n}\)を\(\numset{K}^n\)の正規直交基底とする．
  \begin{enumerate}
    \item 線型写像\(T\colon\numset{K}^n\to\numset{K}^n\)，\(T(\vect{x})=\trps{\rowvect{\innerp{\vect{x}}{\vect{e}_1} & \cdots & \innerp{\vect{x}}{\vect{e}_n}}}\)を\(\basis{B}\)に関する\termdef{分析作用素}（analysis operator）という．
    \item 線型写像\(\synth{T}\colon\numset{K}^n\to\numset{K}^n\)，\(\synth{T}(\trps{\rowvect{x_1 & \cdots & x_n}})=\sum_{i=1}^nx_i\vect{e}_i\)を\(\basis{B}\)に関する\termdef{合成作用素}（synthesis operator）という．
  \end{enumerate}
\end{definition}

分析作用素と合成作用素が持つ性質は，表現行列に関する条件へと言い換えられる．

\begin{definition}{正規行列，ユニタリ行列}{regular_and_unitary_matrix}\index{せいきぎょうれつ@正規行列}\index{ゆにたりぎょうれつ@ユニタリ行列}
  \(\mat{A}\)を\(n\)次複素正方行列とする．
  \begin{enumerate}
    \item \(\htrps{\mat{A}}\mat{A}=\mat{A}\htrps{\mat{A}}\)であるとき，\(\mat{A}\)を\termdef{正規行列}（normal matrix）という．
    \item \(\htrps{\mat{A}}\mat{A}=\mat{A}\htrps{\mat{A}}=\imat\)であるとき（つまり\(\htrps{\mat{A}}=\mat{A}^{-1}\)であるとき），\(\mat{A}\)を\termdef{ユニタリ行列}（unitary matrix）という．
  \end{enumerate}
\end{definition}

\cref{definition:regular_and_unitary_matrix}から，ユニタリ行列は正規行列である．また，次の命題が成立する．

\begin{proposition}{ユニタリ行列の性質}{}
  \(\mat{U}=\rowvect{\vect{u}_1 & \cdots & \vect{u}_n}\)を\(n\)次複素正方行列とする．このとき，以下の命題は同値である．
  \begin{enumerate}
    \item \(\mat{U}\)はユニタリ行列である．
    \item 集合\(\Set{\vect{u}_1,\dots,\vect{u}_n}\)は\(\numset{C}^n\)の正規直交基底である．
  \end{enumerate}
\end{proposition}

\begin{proof}
  \(\htrps{\mat{U}}\mat{U}=[\midx{a}{i}{j}]\)とおくと
  \[
    \htrps{\mat{U}}\mat{U} = \matrice*{\htrps{\vect{u}_1} \\ \vdots \\ \htrps{\vect{u}_n}}\matrice{\vect{u}_1 & \cdots & \vect{u}_n}
    = \matrice*{\htrps{\vect{u}_1}\vect{u}_1 & \cdots & \htrps{\vect{u}_1}\vect{u}_n \\ \vdots & \ddots & \vdots \\ \htrps{\vect{u}_n}\vect{u}_1 & \cdots & \htrps{\vect{u}_n}\vect{u}_n}
  \]
  なので\(\midx{a}{i}{j}=\htrps{\vect{u}_i}\vect{u}_j=\innerp{\vect{u}_j}{\vect{u}_i}\)である．よって，\(\mat{U}^{-1}=\htrps{\mat{U}}\)であることと，各\(i,j\in\Set{1,\dots,n}\)に対して\(\innerp{\vect{u}_i}{\vect{u}_j}=\kdelta{i}{j}\)であることは同値である．
\end{proof}

\begin{corollary}{}{}
  \(T\colon\numset{C}^n\to\numset{C}^n\)を線型写像とする．このとき，以下の命題は同値である．
  \begin{enumerate}
    \item \(T\)はある正規直交基底に関する分析作用素（合成作用素）である．
    \item 標準基底に関する\(T\)の表現行列はユニタリ行列である．
  \end{enumerate}
\end{corollary}

\section{離散フーリエ変換}

\begin{definition}{離散フーリエ変換}{discrete_fourier_transform}\index{りさんふーりえへんかん@離散フーリエ変換}\index{DFT|see{離散フーリエ変換}}\index{FZn@\(\dft{n}\vect{x}\)}
  各\(\vect{x}=\trps{\rowvect{x_0 & \cdots & x_{n-1}}}\in\numset{C}^n\)に対して，\(\numset{C}^n\)の元
  \[
    \hat{\vect{x}} = \trps{\matrice{\hat{x}_0 & \cdots & \hat{x}_{n-1}}},
    \quad\hat{x}_j = \frac{1}{\sqrt{n}}\sum_{k=0}^{n-1}x_k\napr^{-2\krez\iuni jk/n}
  \]
  を対応づける線型写像\(\dft{n}\colon\numset{C}^n\to\numset{C}^n\)を\termdef{離散フーリエ変換}（Discrete Fourier transform; DFT）という．
\end{definition}

以下では\(\napr^{2\krez\iuni/n}=\cos(2\krez/n)+\iuni\sin(2\krez/n)\)を\(\zeta_n\)，もしくは単に\(\zeta\)と書く．
\(\zeta\)により\(\hat{x}_j\)は\(\hat{x}_j=n^{-1/2}(x_0\zeta^{-0j}+x_1\zeta^{-1j}+\dots+x_{n-1}\zeta^{-(n-1)j})\)と表せる．

\begin{proposition}{}{}
  \(\vect{w}_j=n^{-1/2}\trps{\rowvect{\zeta^{0j} & \cdots & \zeta^{(n-1)j}}}\)とする．
  このとき，集合\(\Set{\vect{w}_0,\dots,\vect{w}_{n-1}}\)は\(\numset{C}^n\)の正規直交基底である．
\end{proposition}

\begin{proof}
  \(\innerp{\vect{w}_i}{\vect{w}_j}=\kdelta{i}{j}\)を示すのはめんどうなので，\(\innerp{\vect{w}_j}{\vect{w}_{j-1}}=0\)のみ示す．
  方程式\(z^n-1=0\)の解は\(z=\zeta^0,\dots,\zeta^{n-1}\)である．よって\(z^n-1=(z-\zeta^0)\dotsm(z-\zeta^{n-1})\)だから，\(n-1\)次の係数を比較すると\(\zeta^0+\dots+\zeta^{n-1}=0\)が得られる．したがって
  \[
    \innerp{\vect{w}_j}{\vect{w}_{j-1}} = \sum_{k=0}^{n-1}\frac{\zeta^{jk}}{\sqrt{n}}\frac{\conj{\zeta}^{(j-1)k}}{\sqrt{n}}
    = \frac{1}{n}\sum_{k=0}^{n-1}\zeta^k
    = 0
  \]
  である．
\end{proof}

\begin{definition}{多次元離散フーリエ変換}{multidimensional_discrete_fourier_transform}\index{りさんふーりえへんかん@離散フーリエ変換!たじげん@多次元}\index{FZdn@\(\dft[d]{\vect{n}}f\)}
  \(\vect{n}=\trps{\rowvect{n_1 & \cdots & n_d}}\)を自然数の組とし，\(\Omega=\Set{\trps{\rowvect{x_1 & \cdots & x_d}}\given\text{\(x_j\in\numset{Z}\)，\(0\leq x_j<n_j\)（\(1\leq j\leq d\)）}}\)，\(\mat{N}=\diag(n_1,\dots,n_d)\)とおく．
  関数\(f\colon\Omega\to\numset{C}\)に対して，関数
  \[
    \hat{f}(\vect{\nu}) = \frac{1}{\sqrt{\det\mat{N}}}\sum_{\vect{x}\in\Omega}f(\vect{x})\napr^{-2\krez\iuni\trps{\vect{\nu}}\mat{N}^{-1}\vect{x}}\quad(\vect{\nu}\in\Omega)
  \]
  を対応づける線型写像\(\dft[d]{\vect{n}}\colon\numset{C}^\Omega\to\numset{C}^\Omega\)を\termdef{\(d\)次元離散フーリエ変換}という．
\end{definition}

特に\(d=2\)のとき
\begin{align*}
  \hat{f}(\nu_1,\nu_2) &= \frac{1}{\sqrt{n_1n_2}}\sum_{x_2=0}^{n_2-1}\sum_{x_1=0}^{n_1-1}f(x_1,x_2)\napr^{-2\krez\iuni(\nu_1x_1/n_1+\nu_2x_2/n_2)} \\
  &= \frac{1}{\sqrt{n_2}}\sum_{x_2=0}^{n_2-1}\pqty*{\frac{1}{\sqrt{n_1}}\sum_{x_1=0}^{n_1-1}f(x_1,x_2)\napr^{-2\krez\iuni\nu_1x_1/n_1}}\napr^{-2\krez\iuni\nu_2x_2/n_2}
\end{align*}
であり，右辺は\(f(x_1,x_2)\)を各変数に関して離散フーリエ変換した形になっている．
より一般に，\(f(x_1,\dots,x_d)\)の\(d\)次元離散フーリエ変換は，\(f(x_1,\dots,x_d)\)を各変数に関して離散フーリエ変換したものと一致する．

\section{最小2乗問題}

\subsection{最小2乗問題}

\subsection{スペクトル定理}

\subsection{特異値分解}

\subsection{擬似逆行列}

\section{多重解像度解析}

\section{主成分分析}

\begin{figure}[htbp]
  \begin{minipage}{\linewidth/2}
    \centering
    \includegraphics{scatter.pdf}
  \end{minipage}%
  \begin{minipage}{\linewidth/2}
    \centering
    \includegraphics{pca.pdf}
  \end{minipage}
\end{figure}

\begin{subappendices}
\section{低ランク近似}
\end{subappendices}

\section*{演習問題}
\addcontentsline{toc}{section}{演習問題}

\end{document}
